---
⭕첫 학습날: 2024-07-07
⭕과목: Kubernetes
⭕교재: 컨테이너 인프라 환경 구축을 위한 쿠버네티스 도커
⭕페이지: P125~
⭕학습정도: 🤔중
❤1일복습여부: true
🧡4일복습여부: true
💛7일복습여부: true
💚14일복습여부: true
🧠장기기억: false
복습: 추가 복습
🛑첫날: "✏첫날 : 2024/07/07"
🛑오늘: "⏰오늘 : 2024/10/27"
🛑첫학습후 몇일째?: 첫 학습 후 ❤112일째❤
🛑4일후: "🥉4일뒤 : 2024/07/11"
🛑7일후: "🥈7일뒤 : 2024/07/14"
🛑14일후: "🥇14일뒤 : 2024/07/21"
4일후: "@2024년 7월 11일"
4일후(text): 2024/07/11
7일후: "@2024년 7월 14일"
7일후(text): 2024/07/14
14일후: "@2024년 7월 21일"
14일후(text): 2024/07/21
오늘1: "@2024년 10월 27일 오후 2:01"
오늘2: 2024/10/27
첫학습날text: 2024/07/07
오늘과 첫학습날 사이: "112"
사이: "112"
"1일차복습여부1,0": "1"
"4일차복습여부1,0": "1"
"7일차복습여부1,0": "1"
"장기기억저장여부1,0": "0"
학습률: "0.6"
진행바: 🟩🟩🟩🟩🟩🟩⬜⬜⬜⬜ 60%
---
[[Kubernetes]] [[DevOps]] 
### 단서 질문

- 쿠버네티스에서 서비스란?
    
    서비스는 클러스터 내에 있는 파드와 안정적인 연결을 위해 도메인이나 고정 IP를 통해 접근하게 해주는 역할을 한다. kube-proxy를 통해 구현된다.
    
- 서비스의 종류 3가지
    - 노드포트
        
        워커 노드의 특정 포트를 열어서 해당 노드로 요청을 보내는 방법. 노드포트에서 받은 요청은 노드 포트 서비스로 전달되어 노드포트 서비스에서 다시 파드로 연결해준다.
        
    - 인그레스
        
        ==**노드포트는 1개의 포트에 1개의 디플로이트만 적용이 가능**==합니다.
        
        인그레스는 노드포트와 달리 고유 주소를 사용해서 요청을 나눕니다. 인그레스 컨트롤러에선 주소에 따라서 어떤 서비스를 사용할지 정하고 이를 통해 파드와 연결합니다.
        
        외부에서 노드 포트로 요청 → 노드 포트에서 인그레스 컨트롤러로 요청 → 인그레스 컨트롤러에선 요청 자원에 따라 해당하는 서비스로 연결 → 해당하는 서비스는 다시 파드로 연결
        
    - 로드밸런서
        
        클러스터 외부에 로드밸런서를 구성하고 로드밸런서로 요청을 보내면 알아서 파드로 할당하는 방식.
        
- 서비스를 만드는 명령어는?
    
    ```Python
    kubectl expose [deployment명] --type=[서비스명] --port=[파드의 인바운드 포트] --name=[서비스명]
    kubectl expose [deployment명] --type=NodePort --port=80 --name=nginx-service
    ```
    
- MetalLB란?
    
    베어메탈로 구성된 장치에서 로드밸런서를 사용할 수 있도록 고안된 프로젝트.
    
    > [!important]  
    > 베어메탈이란? 하이퍼바이저(가상화를 제공하는 툴)엔 두 가지 타입의 가상화 방법이 있는데 Type1을 베어 메탈 Type2를 호스티드(Hosted)라고 한다. 베어메탈은 VMWare, Hyper-V 등이 있습니다. 베어메탈은 호스티드와 달리 운영체제 위에서 동작하는 것이 아닌 하드웨어의 바로 위에서 동작합니다.(운영체제를 통한 동작이 아니라 직접 하드웨어를 제어한다.) 호스티드는 운영체제 위에서 동작합니다.  
    
- HPA란?
    
    Horizontal Pod Autoscaling: 수평적 파드 오토스케일링으로 명시한 자원보다 자원을 많이 사용하면 자동적으로 파드의 개수를 증가시킨다.
    

### 핵심 필기

- 전체 내용 접기
    
    쿠버네티스에서 서비스는 웹 서비스나 네트워크 서비스가 아닌 **외부에서 클러스터에 접근하는 것을 서비스**라고 합니다.
    
    - **3.3.1 가장 간단하게 연결하는 방법: 노드포트(p125)**
        
        워커 노드의 특정 포트(노드 포트)를 열고 해당 포트로 들어오는 모든 요청을 노드 포트 서비스로 전달하는 방법입니다. 그리고 노드 포트는 해당 요청을 처리할 수 있는 파드로 요청을 전달합니다.
        
        **사용자 요청 → 워커 노드 포트 → 노드 포트 서비스 → 워커 노드의 파드**
        
        ![[Untitled 20.png]]
        
        - **파일로 노드 포트 생성하기**
            
            **[실습]**
            
            ```Bash
            # 1. 우선 디플로이먼트를 통해 pod을 배포합니다
            kubectl create deployment np-pods --image=sysnet4admin/echo-hname
            
            # 2. yaml 파일을 이용해 노드 포트 서비스를 실행합니다
            kubectl create -f ~/_Bookk8sInfra/ch3/3.3.1/nodeport.yaml
            
            # 3. yaml 내용 확인하기
            cat ./nodeport.yaml
            # yaml의 내용
            apiVersion: v1
            kind: Service # 서비스입니다.
            metadata:
              name: np-svc
            spec:
              selector:
                app: np-pods 
              ports:
                - name: http
                  protocol: TCP
                  port: 80 # 서비스의 포트다
                  targetPort: 80 # 파드의 열려있는 포트다. 
                  nodePort: 30000 # 워커노드의 입력포트다.
                  # 외부에서 30000포트로 요청하면 이는 서비스인 80포트로 넘어간다. 
                  # 여기서 파드의 포트(target port)로 요청을 전달하는데 
                  # 현재 파드는 웹서비스를 제공하므로 80포트로 전달한다.
                  # nginx 파드는 웹페이지를 리턴한다.
              type: NodePort
              
            # 3. 서비스 목록을 조회합니다.
            kubectl get services
            # 결과
            NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE     SELECTOR
            kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP        5d20h   <none>
            np-svc       NodePort    10.107.121.62   <none>        80:30000/TCP   3s      app=np-pods
            # ip는 클러스터 내부에서 사용하는 사설IP다.
            
            # 4. 노드들의 IP를 조회한다
            kubectl get nodes -o wide
            # 5. 웹브라우저에서 노드의 IP로 접속한다
            192.168.1.101:30000 # 사설IP에 노드포트가 3000이므로 3000을 붙여줬다.
            ```
            
              
              
            
        - **부하 분산 테스트하기(p128)**
            
            디플로이먼트로 생성된 파드에 접속하는 중에 파드의 개수가 늘어나면 어떻게 될까?
            
            우선, 노드 포트를 통해 파드의 요청을 계속 보내겠습니다.
            
            ```Bash
            # 우선 네트워크 요청을 계속 보낸다.
            while true; do sleep 1; curl 192.168.1.101:30000; done;
            
            # scale을 통해 파드의 개수를 늘려보자
            kubectl scale deployments np-pods --replicas=5
            
            # 네트워크 요청 내역을 보면 순서대로 파드가 달라지는 것을 볼 수 있다.
            np-pods-5767d54d4b-hnxkq
            np-pods-5767d54d4b-6fkpd
            np-pods-5767d54d4b-hnxkq
            np-pods-5767d54d4b-hnxkq
            np-pods-5767d54d4b-5blsq
            np-pods-5767d54d4b-hnxkq
            np-pods-5767d54d4b-mwgrp
            np-pods-5767d54d4b-mwgrp
            np-pods-5767d54d4b-5blsq
            np-pods-5767d54d4b-mwgrp
            np-pods-5767d54d4b-hnxkq
            np-pods-5767d54d4b-6fkpd
            np-pods-5767d54d4b-6fkpd
            np-pods-5767d54d4b-hnxkq
            np-pods-5767d54d4b-qrp8l
            np-pods-5767d54d4b-mwgrp
            np-pods-5767d54d4b-qrp8l
            np-pods-5767d54d4b-6fkpd
            ```
            
            어떻게 위처럼 외부에서 접속할 때 서비스가 추가된 파드로 작업을 할당할까요?
            
            노드포트의 오브젝트 스펙에 적힌 np-pods와 디플로이먼트의 이름을 확인해 동일하면 같은 파드라고 간주하기 때문입니다.
            
            추적 방법은 이외에도 많지만 여기선 간단하게 이름으로 진행했습니다.
            
            ```Bash
            # nodeport.yaml
            # 노드포트 서비스를 만들기 위해 사용된 파일
            spec:
            	selector:
            	app: np-pods
            ```
            
        - **expose로 노드 포트 서비스 생성하기(p130)**
            
            expose 명령어를 통해서 노드 포트를 만들 수 있습니다.
            
            ```Bash
            kubectl expose deployment \
            np-pods \ # 내보낼 디플로이먼트를 지정한다. 현재 np-pods 디플로이먼트로 nginx 파드를 제공중
            --type=NodePort \
            --name=np-svc-v2 \
            --port=80 \ # 파드의 인바운드 포트
            service/np-svc-v2 exposed
            ```
            
    - **3.3.2 사용 목적별로 연결하는 인그레스(p131)**
        
        노드 포트 서비스는 1개의 노드 포트에 1개의 디플로이먼트만 적용 가능합니다.(노드포트 서비스는 30000~32767 중에 하나의 포트 번호를 사용합니다)
        
        그렇다면 디플로이먼트 마다 포트를 하나씩 사용하는 문제가 발생합니다.
        
        ```Bash
        # 30000~32767 사이에 포트 번호를 지정한다.
        # 지정 안하면 랜덤하게 사용하고 지정하면 해당 포트를 사용한다.
        kubectl expose deployment [디플로이먼트명] --type=NodePort \
        --port=[파드의 인바운드 포트]\ # 노드포트의 포트번호와는 다른 용도
        --name=[서비스의 이름]
        ```
        
          
        
        **인그레스(Ingress)**는 고유한 주소를 사용하여 사용 목적에 따라 다른 응답 제공이 가능합니다. 또한 트래픽에 대한 L4/L7 로드밸런서와 보안 인증서를 처리하는 기능을 제공합니다.
        
        인그레스를 사용하려면 인그레스 컨트롤러가 필요합니다. 이번 실습에선 쿠버네티스에서 제공하는 nginx 인그레스 컨트롤러를 사용합니다
        
          
        
        **인그레스 동작 방식**
        
        1. 외부에서 노드 포트로 요청을 합니다.
        2. 노드 포트 서비스가 아닌 인그레스 컨트롤러 서비스로 전달합니다.(노드포트 방식과 달리 노드 포트 서비스의 역할을 인그레스 컨트롤러 서비스가 한다)
        3. 인그레스 컨트롤러 서비스는 요청에 맞는 클러스터 IP 서비스로 요청을 전달합니다.
        4. 클러스터 IP 서비스는 사용자를 해당 파드로 연결해줍니다.
        
        ![[Untitled 1 7.png]]
        
          
        
        **[실습]**
        
        ```Bash
        # deployment 두 개 생성
        kubectl create deployment in-hname-pod --image=sysnet4admin/echo-hname
        kubectl create deployment in-ip-pod --image=sysnet4admin/echo-ip
        
        # 인그레스 컨트롤러 생성
        kubectl apply -f ./ingress-nginx.yaml
        
        # 인그레스 컨트롤러의 파드가 배포됐는지 확인하기
        # NGINX 인그레스 컨트롤러는 default 네임스페이스가 아닌 ingress-nginx 네임스페이스에 속한다.
        # 따라서, n 옵션으로 ingress-nginx를 추가해야합니다.
        # -n 옵션은 default 네임스페이스가 아닌 다른 네임스페이스를 확인할 때 사용됩니다.
        # 파드뿐만 아니라 서비스를 확인할 때도 동일한 옵션을 줍니다.
        kubectl get pods -n ingress-nginx
        
        # 사용자 요구에 맞게 경로와 작동을 정의합니다.
        kubectl apply -f ./ingress-config.yaml
        ```
        
        ![[Untitled 2 5.png]]
        
        ![[Untitled 3 4.png]]
        
        ```Bash
        
        # 인그레스 설정 파일이 제대로 등록됐는지 확인합니다
        kubectl get ingress
        
        # 인그레스 적용된 내용을 야믈 형식으로 출력합니다.
        kubectl get ingress -o yaml
        
        # 위에서 인그레스 컨트롤러 생성과 인그레스 설정을 완료했습니다.
        # 이제 노드포트 서비스로 인그레스 컨트롤러를 외부에 노출합니다.
        kubectl apply ../ingress.yaml
        # ingress 파일 내용
        apiVersion: v1
        kind: Service
        metadata:
          name: nginx-ingress-controller
          namespace: ingress-nginx
        spec:
          ports:
          - name: http
            protocol: TCP
            port: 80
            targetPort: 80
            nodePort: 30100 # 워커 노드의 포트 번호
          - name: https
            protocol: TCP
            port: 443
            targetPort: 443
            nodePort: 30101
          selector:
            app.kubernetes.io/name: ingress-nginx
          type: NodePort
          
          # 이제 서비스가 등록됐는지 확인합니다. 단, 네임스페이스를 ingress-nginx로 등로갷ㅆ으므로
          # 해당 네임스페이스로 검색합니다.
          kubectl get services -n ingress-nginx
          
          # 이제 컨트롤러가 등록됐으므로 해당 서비스와 디플로이먼트를 연결합니다.
          kubectl expose deployment in-hname-pod --name=hname-svc-default --port=80,443
          kubectl expose deployment in-ip-pod --name=ip-svc --port=80,443
          # 생성된 서비스를 통해 디플로이먼트들이 노출됐는지 확인합니다. 
          # 새로 생성된 서비스는 default 네임스페이스에 있으므로 n 옵션은 필요 없습니다.
          kubectl get services
          kubectl get endpoints
          
          # 이제 요청을 보냅니다
          curl 192.168.1.101:30100
          in-hname-pod-8565c86448-8krdz
        	
        	# ip 경로로 요청을 보냅니다.
        	# in-ip-pod의 경로로 요청을 보냅니다.
        	curl 192.168.1.101:30100/ip
        	request_method : GET | ip_dest: 172.16.221.175
        	
        	kubectl get pods -o wide
        	# 결과
        	NAME                            IP               NODE     NOMINATED NODE   READINESS GATES
        	in-hname-pod-8565c86448-8krdz   172.16.132.26    w3-k8s   <none>           <none>
        	in-ip-pod-76bf6989d-cwk6n       172.16.221.175   w1-k8s   <none>           <none>
        	
        ```
        
    - **3.3.3 클라우드에서 쉽게 구성 가능한 로드밸런서**
        
        지금까지 방식은 워커 노드의 노드포트를 통해 접속하고 이를 노드포트 서비스가 파드 서비스로 포워딩하는 방식이었습니다. 이런 방법보다는 바로 서비스의 요청하고 이를 파드 서비스로 연결해주면 안될까요? 쿠버네티스의 **로드밸런서(LoadBalancer)**를 사용하면 가능합니다.
        
        **노드포트 & 인그레스** 흐름도: 워커 노드의 포트로 요청 → 서비스로 전달 → 서비스에서 파드로 요청
        
        **로드밸런서** 흐름도: 로드밸런서로 요청 → 로드밸런서에서 파드로 요청
        
        ![[Untitled 4 4.png]]
        
        단, 로드밸런서 방식은 쿠버네티스 클러스터 내에서 만드는 게 아닌 쿠버네티스 외부에서 설정해야 합니다. 만약, 클라우드에서 제공하는 쿠버네티스를 사용한다면 아래와 같이 선언만 하면 됩니다.
        
        ```Bash
        kubectl expose deployment ex-1b --type=loadBalancer --name=ex-svc
        ```
        
          
        
    - **3.3.4 온프로미스에서 로드밸런서를 구성하는 MetalLB**
        
        그렇다면 클라우드가 아닌 온프로미스에서 로드밸런서를 사용할 수는 없을까요?
        
        온프로미스에서 로드밸런서 서비스를 사용하기 위해서는 로드밸런서 서비스를 받아주는 구성이 필요합니다. 이를 지원하는 것이 **MetalLB**입니다.
        
        MetalLB란 베어메탈(운영체제가 설치되지 않은 하드웨어)로 구성된 쿠버네티스에서도 로드밸런서를 사용할 수 있게 고안된 프로젝트입니다. MetalLB는 L2 네트워크와 L3 네트워크로 로드밸런서를 구현합니다.
        
        ![[Untitled 5 2.png]]
        
        ```Bash
        # 1. deployment 만들기
        kubectl create deployment lb-hname-pods --image=sysnet4admin/echo-hname
        kubectl scale deployment lb-hname-pods --replicas=3
        
        kubectl create deployment lb-ip-pods --image=sysnet4admin/echo-ip
        kubectl scale deployment lb-ip-pods --replicas=3
        
        # 2. 사전 정의한 yaml 파일로 MetalLB 구성하기
        kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.4/metallb.yaml
        cat ~/_Book_k8sInfra/ch3/3.3.4/metallb.yaml
        
        # 3. 배포된 MetalLB의 파드가 5개(controller 1개, speaker 4개)인지 확인.
        kubectl get pods -n metallb-system -o wide
        # 결과
        NAME                          READY   STATUS    RESTARTS   AGE    IP              NODE     NOMINATED NODE   READINESS GATES
        controller-5d48db7f99-grswx   1/1     Running   0          112s   172.16.132.27   w3-k8s   <none>           <none>
        speaker-8b755                 1/1     Running   0          112s   192.168.1.103   w3-k8s   <none>           <none>
        speaker-j5d69                 1/1     Running   0          112s   192.168.1.101   w1-k8s   <none>           <none>
        speaker-nrmrh                 1/1     Running   0          112s   192.168.1.102   w2-k8s   <none>           <none>
        speaker-rbkgn                 1/1     Running   0          112s   192.168.1.10    m-k8s    <none>           <none>
        
        # 4. MetalLB 설정 적용하기
        kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.4/metallb.yaml
        
        # ConfigMap 생성 여부 확인
        kubectl get configmap -n metallb-system
        NAME     DATA   AGE
        config   1      18m
        
        [root@m-k8s 3.3.4]# kubectl get configmap -n metallb-system -o yaml
        apiVersion: v1
        items:
        - apiVersion: v1
          data:
            config: |
              address-pools:
              - name: nginx-ip-range
                protocol: layer2
                addresses:
                - 192.168.1.11-192.168.1.13
          kind: ConfigMap
          metadata:
            annotations:
              kubectl.kubernetes.io/last-applied-configuration: |
                {"apiVersion":"v1","data":{"config":"address-pools:\n- name: nginx-ip-range\n  protocol: layer2\n  addresses:\n  - 192.168.1.11-192.168.1.13\n"},"kind":"ConfigMap","metadata":{"annotations":{},"name":"config","namespace":"metallb-system"}}
            creationTimestamp: "2024-07-05T01:59:14Z"
            managedFields:
            - apiVersion: v1
              fieldsType: FieldsV1
              fieldsV1:
                f:data:
                  .: {}
                  f:config: {}
                f:metadata:
                  f:annotations:
                    .: {}
                    f:kubectl.kubernetes.io/last-applied-configuration: {}
              manager: kubectl
              operation: Update
              time: "2024-07-05T01:59:14Z"
            name: config
            namespace: metallb-system
            resourceVersion: "204098"
            selfLink: /api/v1/namespaces/metallb-system/configmaps/config
            uid: c6444340-0452-4d38-a2f8-50bd7281a1ac
        kind: List
        metadata:
          resourceVersion: ""
          selfLink: ""
        
        # 모든 설정이 완료됐으므로 디플로이먼트를 로드밸런서 서비스로 노출합니다.
        kubectl expose deployment lb-hname-pods --type=LoadBalancer --name=lb-hname-svc --port=80
        kubectl expose deployment lb-ip-pods --type=LoadBalancer --name=lb-ip-svc --port=80
        kubectl get services
        ```
        
        ![[Untitled 6 2.png]]
        
    - **3.3.5 부하에 따라 자동으로 파드 수를 조절하는 HPA(P143)**
        
        **HPA(Horizontal Pod Autoscaler)**는 부하량에 따라 디플로이먼트의 파드의 개수를 유동적으로 조절합니다.
        
          
        
        **실습**
        
        1. 실습을 위해 파드를 생성합니다.
        
        ```Bash
        kubectl create deployment lb-hname-pods --image=sysnet4admin/echo-hname
        ```
        
        1. MetalLB 설정은 이전 실습에 했으므로 이를 이용해 디플로이먼트와 서비스를 연결합니다.
        
        ```Bash
        kubectl expose deployment lb-hname-pods --name=hpa-hname-svc --type=LoadBalancer --port=80
        ```
        
        1. 설정된 로드 밸런서 서비스와 부여된 IP를 확인합니다.
        
        ```Bash
        [root@m-k8s 3.3.4]# kubectl get services
        NAME            TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)        AGE
        hpa-hname-svc   LoadBalancer   10.103.82.115   192.168.1.11   80:31870/TCP   3m6s
        kubernetes      ClusterIP      10.96.0.1       <none>         443/TCP        7d3h
        ```
        
        1. 파드의 자원량을 파악합니다.
        
        ```Bash
        [root@m-k8s 3.3.4]# kubectl top pods
        Error from server (NotFound): the server could not find the requested resource (get services http:heapster:)
        # 힙스터는 매트릭 서버 이전에 사용된 모니터링 도구
        ```
        
        1. 에러가 발생합니다. 왜냐면 HPA는 **메트릭 서버(Metrics-Server)**를 통해서 얻은 파드의 계측값을 이용합니다. 현재 매트릭 서버가 존재하지 않으므로 문제가 발생합니다.
        
        ![[Untitled 7 2.png]]
        
        1. 메트릭 서버를 생성합니다.
        
        ```Bash
        kubectl create -f ~/_Book_k8sInfra/ch3/3.3.5/metrics-server.yaml
        ```
        
        1. top 명령어를 통해 사용 자원을 확인합니다.
        
        ```Bash
        [root@m-k8s 3.3.4]# kubectl top pods
        NAME                             CPU(cores)   MEMORY(bytes)   
        lb-hname-pods-79b95c7c7b-7t2rm   0m           2Mi  
        ```
        
        1. 현재는 HPA 파드 증설 시점(scale)을 설정하지 않아 증실 시점을 알 수 없습니다. 따라서, 파드에 부하가 걸리기 전에 scale이 실행되게 디플로이먼트에 기준 값을 기록합니다. 이 때 디플로이먼트를 삭제하고 새로 배포하지 않고 기존에 배포한 디플로이먼트 내용을 수정할 수 있는 edit 명령어를 사용합니다.
        
        ```Bash
        kubectl edit deployment hpa-hname-pods 
        ```
        
        위 명령어 실행 결과로 아래 내용이 옵니다.
        
        ![[Untitled 8 2.png]]
        
        여기서 사용하는 m은 milliunits으로 1000m이 1개의 CPU가 됩니다. 따라서, 1m은 0.001 CPU가 됩니다.
        
        **requests**는 파드 사용을 위한 자원 예약입니다. 이 requests들의 총합이 총 자원을 넘어서면 파드를 생성할 수 없습니다.
        
        **limits**는 파드가 사용할 수 있는 최대 자원입니다. 이 이상을 사용하지 못하게 방지합니다.
        
          
        
        1. 오토스케일링을 설정해서 파드의 개수를 자동으로 늘려줍니다.
        
        ```Bash
        kubectl autoscale deployment hpa-hname-pods \
        --min=1 \
        --max=30 \
        --cpu-percent=50
        horizontalpodautoscaler.autoscaling/hpa-hname-pods autoscaled
        ```
        
        위의 설정에선 CPU의 사용률이 50프로 이상이면 파드 오토스케일링을 시작합니다.
        
        deployment에서 request를 통해 cpu는 10m를 사용합니다. 10m의 50%인 5m를 초과하면 오토스케일링을 시작합니다.
        
        예를 들어, 29m을 사용하게 된다면 어떻게 될까요?
        
        10m의 50%인 5m으로 전체 사용량을 나눕니다. 29m/5m=5.8 따라서, 5.8개보다 많은 파드가 필요합니다. 따라서, HPA에선 총 파드의 개수가 6개가 되도록 파드를 생성합니다.
        
        ```Bash
        kubectl get pods
        # 결과
        NAME                              READY   STATUS    RESTARTS   AGE
        hpa-hname-pods-696b8fcc99-2dwrk   1/1     Running   0          6m32s
        hpa-hname-pods-696b8fcc99-7fc8s   1/1     Running   0          6m32s
        hpa-hname-pods-696b8fcc99-9nq55   1/1     Running   0          6m32s
        hpa-hname-pods-696b8fcc99-bjhtp   1/1     Running   0          6m47s
        hpa-hname-pods-696b8fcc99-gtjrv   1/1     Running   0          6m47s
        hpa-hname-pods-696b8fcc99-lm67c   1/1     Running   0          6m47s
        hpa-hname-pods-696b8fcc99-rzrmd   1/1     Running   0          101m
        ```
        
        이후에 더 이상 부하가 발생하지 않으면 파드는 최소 조건인 파드 1개의 상태로 돌아갑니다.
        
        6분정도 걸린듯?
        

### 핵심 요약

- 핵심 요약 접기
    - 학습내용을 몇문장으로 압축하여 정리한다.
- AI 요약
    
    쿠버네티스의 서비스는 클러스터 내 파드와의 안정적인 연결을 제공합니다. 주요 서비스 유형으로는 ClusterIP, NodePort, LoadBalancer가 있습니다. LoadBalancer 서비스는 외부 로드 밸런서와 연동되며, MetalLB를 통해 베어메탈 환경에서도 구현 가능합니다. HPA(Horizontal Pod Autoscaler)는 부하에 따라 파드 수를 자동으로 조절하며, 메트릭 서버를 통해 파드의 자원 사용량을 모니터링합니다. CPU 사용률 등을 기준으로 파드를 스케일링하여 효율적인 리소스 관리를 가능하게 합니다.
    
    이를 통해 쿠버네티스는 동적인 워크로드에 효과적으로 대응할 수 있습니다. 서비스와 HPA를 함께 활용하면 안정적이고 확장 가능한 애플리케이션 배포가 가능해집니다. 이러한 기능들은 쿠버네티스의 강력한 오케스트레이션 능력을 보여주는 좋은 예시입니다.
    

### 복습알림

- 
- 자동으로 핸드폰에 알림이 오도록 설정하고 싶으면 다음과 같이 한다.

> [!important]  
> 